(pytorch_venv6) lixiaoya@gpuserver003:~/mrc-for-flat-nested-ner/script$ bash zhonto_mrc_train2.sh 
Please notice that merge the args_dict and json_config ... ...
{
  "bert_frozen": "false",
  "hidden_size": 768,
  "hidden_dropout_prob": 0.2,
  "classifier_sign": "multi_nonlinear",
  "clip_grad": 1,
  "bert_config": {
    "attention_probs_dropout_prob": 0.1,
    "directionality": "bidi",
    "hidden_act": "gelu",
    "hidden_dropout_prob": 0.1,
    "hidden_size": 768,
    "initializer_range": 0.02,
    "intermediate_size": 3072,
    "max_position_embeddings": 512,
    "num_attention_heads": 12,
    "num_hidden_layers": 12,
    "pooler_fc_size": 768,
    "pooler_num_attention_heads": 12,
    "pooler_num_fc_layers": 3,
    "pooler_size_per_head": 128,
    "pooler_type": "first_token_transform",
    "type_vocab_size": 2,
    "vocab_size": 21128
  },
  "config_path": "/home/lixiaoya/mrc-for-flat-nested-ner/config/zh_bert.json",
  "data_dir": "/data/nfsdata2/xiaoya/dataset/mrc-ner/zh_ontonotes4",
  "bert_model": "/data/nfsdata/nlp/BERT_BASE_DIR/chinese_L-12_H-768_A-12",
  "task_name": null,
  "max_seq_length": 100,
  "train_batch_size": 16,
  "dev_batch_size": 32,
  "test_batch_size": 32,
  "checkpoint": 300,
  "learning_rate": 8e-06,
  "num_train_epochs": 6,
  "warmup_proportion": -1.0,
  "local_rank": -1,
  "gradient_accumulation_steps": 1,
  "seed": 2333,
  "export_model": true,
  "output_dir": "/data/xiaoya/export_dir/mrc-ner/zh_onto/2020-05-07-100-8e-6-16-1-0.2",
  "data_sign": "zh_onto",
  "weight_start": 1.0,
  "weight_end": 1.0,
  "weight_span": 1.0,
  "entity_sign": "flat",
  "n_gpu": 1,
  "dropout": 0.2
}
-*--*--*--*--*--*--*--*--*--*-
current data_sign: zh_onto
62896
17204
17384
loading train data
62896 train data loaded
loading dev data
17204 dev data loaded
loading test data
17384 test data loaded
######################################################################
EPOCH:  0
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.012256842106580734
............................................................
DEV: loss, acc, precision, recall, f1
0.0152 0.7858 0.6222 0.6945 0.6564
SAVED model path is :
/data/xiaoya/export_dir/mrc-ner/zh_onto/2020-05-07-100-8e-6-16-1-0.2/bert_finetune_model_0_300.bin
............................................................
TEST: loss, acc, precision, recall, f1
0.0158 0.7755 0.6292 0.702 0.6636
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.006907797418534756
............................................................
DEV: loss, acc, precision, recall, f1
0.0119 0.8161 0.7734 0.6214 0.6891
SAVED model path is :
/data/xiaoya/export_dir/mrc-ner/zh_onto/2020-05-07-100-8e-6-16-1-0.2/bert_finetune_model_0_600.bin
............................................................
TEST: loss, acc, precision, recall, f1
0.0121 0.8089 0.7835 0.6397 0.7043
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.0044604456052184105
............................................................
DEV: loss, acc, precision, recall, f1
0.0114 0.808 0.7924 0.638 0.7069
SAVED model path is :
/data/xiaoya/export_dir/mrc-ner/zh_onto/2020-05-07-100-8e-6-16-1-0.2/bert_finetune_model_0_900.bin
............................................................
TEST: loss, acc, precision, recall, f1
0.0116 0.7978 0.7972 0.6623 0.7235
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.001023147371597588
............................................................
DEV: loss, acc, precision, recall, f1
0.0106 0.8378 0.7186 0.7744 0.7454
SAVED model path is :
/data/xiaoya/export_dir/mrc-ner/zh_onto/2020-05-07-100-8e-6-16-1-0.2/bert_finetune_model_0_1200.bin
............................................................
TEST: loss, acc, precision, recall, f1
0.0109 0.8302 0.7236 0.7891 0.755
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.0035902000963687897
............................................................
DEV: loss, acc, precision, recall, f1
0.0102 0.8198 0.8096 0.6454 0.7182
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.003018076065927744
............................................................
DEV: loss, acc, precision, recall, f1
0.0096 0.8502 0.7922 0.7583 0.7748
SAVED model path is :
/data/xiaoya/export_dir/mrc-ner/zh_onto/2020-05-07-100-8e-6-16-1-0.2/bert_finetune_model_0_1800.bin
............................................................
TEST: loss, acc, precision, recall, f1
0.0096 0.8414 0.8023 0.7718 0.7867
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.0002713368448894471
............................................................
DEV: loss, acc, precision, recall, f1
0.0093 0.8546 0.7627 0.8056 0.7835
SAVED model path is :
/data/xiaoya/export_dir/mrc-ner/zh_onto/2020-05-07-100-8e-6-16-1-0.2/bert_finetune_model_0_2100.bin
............................................................
TEST: loss, acc, precision, recall, f1
0.0094 0.8464 0.7685 0.8139 0.7905
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.0026012209709733725
............................................................
DEV: loss, acc, precision, recall, f1
0.0103 0.8335 0.8578 0.6563 0.7437
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.001698926673270762
............................................................
DEV: loss, acc, precision, recall, f1
0.0096 0.838 0.8348 0.6883 0.7545
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.008568448014557362
............................................................
DEV: loss, acc, precision, recall, f1
0.0097 0.8688 0.7884 0.8116 0.7999
SAVED model path is :
/data/xiaoya/export_dir/mrc-ner/zh_onto/2020-05-07-100-8e-6-16-1-0.2/bert_finetune_model_0_3000.bin
............................................................
TEST: loss, acc, precision, recall, f1
0.0095 0.8647 0.791 0.83 0.81
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.007631239015609026
............................................................
DEV: loss, acc, precision, recall, f1
0.0094 0.8579 0.8173 0.7574 0.7862
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.00039579253643751144
............................................................
DEV: loss, acc, precision, recall, f1
0.0099 0.8559 0.8033 0.7638 0.783
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.005443254951387644
............................................................
DEV: loss, acc, precision, recall, f1
0.0093 0.8558 0.8243 0.7442 0.7822
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
######################################################################
EPOCH:  1
current learning rate 7.599999999999999e-06
current learning rate 7.599999999999999e-06
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.001608582097105682
............................................................
DEV: loss, acc, precision, recall, f1
0.0102 0.8706 0.8055 0.8036 0.8045
SAVED model path is :
/data/xiaoya/export_dir/mrc-ner/zh_onto/2020-05-07-100-8e-6-16-1-0.2/bert_finetune_model_1_300.bin
............................................................
TEST: loss, acc, precision, recall, f1
0.0102 0.8663 0.8111 0.8254 0.8182
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
7.780924352118745e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0097 0.8703 0.8162 0.7977 0.8069
SAVED model path is :
/data/xiaoya/export_dir/mrc-ner/zh_onto/2020-05-07-100-8e-6-16-1-0.2/bert_finetune_model_1_600.bin
............................................................
TEST: loss, acc, precision, recall, f1
0.0095 0.8715 0.8159 0.8249 0.8204
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
5.67670285818167e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0104 0.8698 0.8172 0.7824 0.7994
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.00041134338243864477
............................................................
DEV: loss, acc, precision, recall, f1
0.0108 0.8518 0.8417 0.707 0.7685
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.0009587244130671024
............................................................
DEV: loss, acc, precision, recall, f1
0.0106 0.8546 0.8281 0.7336 0.778
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.0007586980937048793
............................................................
DEV: loss, acc, precision, recall, f1
0.0109 0.8579 0.7431 0.8386 0.788
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.0006691239541396499
............................................................
DEV: loss, acc, precision, recall, f1
0.01 0.8761 0.8036 0.8064 0.805
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.0021433206275105476
............................................................
DEV: loss, acc, precision, recall, f1
0.01 0.8702 0.7925 0.8136 0.8029
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.0006592314457520843
............................................................
DEV: loss, acc, precision, recall, f1
0.0105 0.8632 0.8353 0.751 0.7909
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.0007590530440211296
............................................................
DEV: loss, acc, precision, recall, f1
0.0098 0.869 0.8089 0.7922 0.8004
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.0007129219593480229
............................................................
DEV: loss, acc, precision, recall, f1
0.0101 0.8733 0.8043 0.8112 0.8078
SAVED model path is :
/data/xiaoya/export_dir/mrc-ner/zh_onto/2020-05-07-100-8e-6-16-1-0.2/bert_finetune_model_1_3300.bin
............................................................
TEST: loss, acc, precision, recall, f1
0.01 0.8745 0.8103 0.8327 0.8213
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.00046511442633345723
............................................................
DEV: loss, acc, precision, recall, f1
0.011 0.8623 0.8193 0.76 0.7885
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.00338360364548862
............................................................
DEV: loss, acc, precision, recall, f1
0.0094 0.8587 0.8057 0.7769 0.791
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
######################################################################
EPOCH:  2
current learning rate 7.219999999999999e-06
current learning rate 7.219999999999999e-06
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.0007595429196953773
............................................................
DEV: loss, acc, precision, recall, f1
0.011 0.8689 0.8053 0.8065 0.8059
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.0003636609762907028
............................................................
DEV: loss, acc, precision, recall, f1
0.012 0.8608 0.8045 0.783 0.7936
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.02834632247686386
............................................................
DEV: loss, acc, precision, recall, f1
0.011 0.8575 0.805 0.7742 0.7893
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.0019933697767555714
............................................................
DEV: loss, acc, precision, recall, f1
0.0139 0.8441 0.8498 0.6815 0.7564
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.0010827836813405156
............................................................
DEV: loss, acc, precision, recall, f1
0.012 0.8657 0.8241 0.7742 0.7984
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.0010112534509971738
............................................................
DEV: loss, acc, precision, recall, f1
0.0105 0.8638 0.8118 0.7822 0.7967
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
1.8236371033708565e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0117 0.8719 0.8135 0.7956 0.8044
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.002244058297947049
............................................................
DEV: loss, acc, precision, recall, f1
0.0106 0.8663 0.812 0.7876 0.7996
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
8.083979628281668e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0123 0.8583 0.8334 0.7408 0.7844
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.0006909375661052763
............................................................
DEV: loss, acc, precision, recall, f1
0.0122 0.8534 0.8132 0.7713 0.7917
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.00888573843985796
............................................................
DEV: loss, acc, precision, recall, f1
0.0123 0.8643 0.7953 0.8073 0.8012
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.0006346299778670073
............................................................
DEV: loss, acc, precision, recall, f1
0.0115 0.8627 0.8144 0.7858 0.7998
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.0006731993053108454
............................................................
DEV: loss, acc, precision, recall, f1
0.0115 0.8581 0.807 0.7752 0.7908
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
######################################################################
EPOCH:  3
current learning rate 6.858999999999998e-06
current learning rate 6.858999999999998e-06
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.00010191474575549364
............................................................
DEV: loss, acc, precision, recall, f1
0.0131 0.8564 0.8053 0.7806 0.7927
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.000267762690782547
............................................................
DEV: loss, acc, precision, recall, f1
0.0136 0.8627 0.7961 0.7884 0.7922
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.0005063272546976805
............................................................
DEV: loss, acc, precision, recall, f1
0.0159 0.8645 0.8093 0.7805 0.7946
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.00013335370749700814
............................................................
DEV: loss, acc, precision, recall, f1
0.0143 0.8553 0.8271 0.7423 0.7824
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.0042555308900773525
............................................................
DEV: loss, acc, precision, recall, f1
0.0122 0.8671 0.8009 0.7912 0.796
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
6.3015136220201384e-06
............................................................
DEV: loss, acc, precision, recall, f1
0.0133 0.8616 0.8106 0.7562 0.7824
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
5.6699976994423196e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0144 0.8658 0.8082 0.7976 0.8029
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.0021486757323145866
............................................................
DEV: loss, acc, precision, recall, f1
0.0122 0.8695 0.8134 0.7821 0.7975
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.00046692072646692395
............................................................
DEV: loss, acc, precision, recall, f1
0.0131 0.867 0.8172 0.7688 0.7923
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.003047206439077854
............................................................
DEV: loss, acc, precision, recall, f1
0.0133 0.8658 0.7943 0.7995 0.7969
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.0013012354029342532
............................................................
DEV: loss, acc, precision, recall, f1
0.0139 0.8622 0.8061 0.7814 0.7936
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.00012311781756579876
............................................................
DEV: loss, acc, precision, recall, f1
0.0147 0.8462 0.7759 0.8011 0.7883
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.00038673743256367743
............................................................
DEV: loss, acc, precision, recall, f1
0.0161 0.8562 0.8221 0.742 0.78
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
######################################################################
EPOCH:  4
current learning rate 6.516049999999998e-06
current learning rate 6.516049999999998e-06
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.00030748729477636516
............................................................
DEV: loss, acc, precision, recall, f1
0.0166 0.8635 0.8004 0.7853 0.7928
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.00025941026979126036
............................................................
DEV: loss, acc, precision, recall, f1
0.016 0.8632 0.8026 0.7841 0.7933
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
5.1610088121378794e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0166 0.8668 0.8108 0.7868 0.7986
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.00016008607053663582
............................................................
DEV: loss, acc, precision, recall, f1
0.0165 0.8684 0.8192 0.7692 0.7934
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.0005544761079363525
............................................................
DEV: loss, acc, precision, recall, f1
0.0163 0.8437 0.7749 0.7938 0.7843
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.0032671450171619654
............................................................
DEV: loss, acc, precision, recall, f1
0.0156 0.8599 0.7871 0.796 0.7916
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.0003602270153351128
............................................................
DEV: loss, acc, precision, recall, f1
0.0152 0.861 0.8111 0.7693 0.7897
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
6.069069422665052e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0154 0.863 0.8017 0.7899 0.7958
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
9.208770643454045e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0184 0.8518 0.8302 0.7266 0.7749
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.00017188533092848957
............................................................
DEV: loss, acc, precision, recall, f1
0.0165 0.861 0.8128 0.767 0.7893
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.00014707892842125148
............................................................
DEV: loss, acc, precision, recall, f1
0.0162 0.8612 0.809 0.7715 0.7898
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
6.34527241345495e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0166 0.8636 0.8151 0.7786 0.7964
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.00012930220691487193
............................................................
DEV: loss, acc, precision, recall, f1
0.0176 0.8572 0.7995 0.7772 0.7882
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
######################################################################
EPOCH:  5
current learning rate 6.190247499999998e-06
current learning rate 6.190247499999998e-06
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.00016762118320912123
............................................................
DEV: loss, acc, precision, recall, f1
0.0182 0.8612 0.8232 0.7599 0.7903
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.00022880219330545515
............................................................
DEV: loss, acc, precision, recall, f1
0.0174 0.8571 0.8175 0.7537 0.7843
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.00018825846200343221
............................................................
DEV: loss, acc, precision, recall, f1
0.0177 0.854 0.8442 0.7201 0.7772
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
4.150910172029398e-06
............................................................
DEV: loss, acc, precision, recall, f1
0.0171 0.8509 0.8304 0.7397 0.7824
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.00031966756796464324
............................................................
DEV: loss, acc, precision, recall, f1
0.0184 0.8584 0.8114 0.764 0.787
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.00011813252058345824
............................................................
DEV: loss, acc, precision, recall, f1
0.0188 0.8647 0.8243 0.7707 0.7966
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.0012644290691241622
............................................................
DEV: loss, acc, precision, recall, f1
0.0177 0.8656 0.7913 0.8115 0.8013
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
4.082315626874333e-06
............................................................
DEV: loss, acc, precision, recall, f1
0.0172 0.8648 0.8245 0.7728 0.7978
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.00029044970870018005
............................................................
DEV: loss, acc, precision, recall, f1
0.0181 0.859 0.8076 0.7807 0.7939
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.0001283867604797706
............................................................
DEV: loss, acc, precision, recall, f1
0.0163 0.8629 0.7909 0.7988 0.7948
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
5.76648126298096e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0151 0.863 0.805 0.7846 0.7947
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
9.818612306844443e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0166 0.8642 0.8309 0.7581 0.7928
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
4.737314611702459e-06
............................................................
DEV: loss, acc, precision, recall, f1
0.016 0.8695 0.7955 0.8027 0.799
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
=&==&==&==&==&==&==&==&==&==&==&==&==&==&==&=
Best DEV : overall best loss, acc, precision, recall, f1 
0.0101 0.8733 0.8043 0.8112 0.8078
scores on TEST when Best DEV:loss, acc, precision, recall, f1 
0.01 0.8745 0.8103 0.8327 0.8213
=&==&==&==&==&==&==&==&==&==&==&==&==&==&==&=