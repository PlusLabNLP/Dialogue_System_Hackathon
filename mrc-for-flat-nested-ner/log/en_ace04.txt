Please notice that merge the args_dict and json_config ... ...
{
  "bert_frozen": "false",
  "hidden_size": 768,
  "hidden_dropout_prob": 0.2,
  "classifier_sign": "multi_nonlinear",
  "clip_grad": 1,
  "bert_config": {
    "attention_probs_dropout_prob": 0.1,
    "hidden_act": "gelu",
    "hidden_dropout_prob": 0.1,
    "hidden_size": 768,
    "initializer_range": 0.02,
    "intermediate_size": 3072,
    "max_position_embeddings": 512,
    "num_attention_heads": 12,
    "num_hidden_layers": 12,
    "type_vocab_size": 2,
    "vocab_size": 30522
  },
  "config_path": "/home/shannon/mrc-for-flat-nested-ner/config/en_bert_base_uncased.json",
  "data_dir": "/home/shannon/dataset/en_ace04_short",
  "bert_model": "/home/shannon/BERT_BASE_DIR/uncased_L-12_H-768_A-12",
  "task_name": null,
  "max_seq_length": 150,
  "train_batch_size": 32,
  "dev_batch_size": 32,
  "test_batch_size": 32,
  "checkpoint": 600,
  "learning_rate": 4e-05,
  "num_train_epochs": 10,
  "warmup_proportion": -1.0,
  "local_rank": -1,
  "gradient_accumulation_steps": 1,
  "seed": 2333,
  "export_model": false,
  "output_dir": "/home/shannon/export_dir/mrc-ner/ace2004/mrc-2020.05.14-150-4e-5-32-18_1",
  "data_sign": "ace2004",
  "weight_start": 1.0,
  "weight_end": 1.0,
  "weight_span": 1.0,
  "entity_sign": "nested",
  "n_gpu": 2,
  "dropout": 0.1
}
-*--*--*--*--*--*--*--*--*--*-
current data_sign: ace2004
=*==*==*==*==*==*==*==*==*==*=
loading train data ... ...
43386
start & end positions are out of bounaries !!!
start & end positions are out of bounaries !!!
start & end positions are out of bounaries !!!
start & end positions are out of bounaries !!!
start & end positions are out of bounaries !!!
start & end positions are out of bounaries !!!
start & end positions are out of bounaries !!!
43386 train data loaded
=*==*==*==*==*==*==*==*==*==*=
loading dev data ... ...
5194
5194 dev data loaded
=*==*==*==*==*==*==*==*==*==*=
loading test data ... ...
5663
5663 test data loaded
######################################################################
EPOCH:  0
/home/shannon/venv/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.003921862691640854
............................................................
DEV: loss, acc, precision, recall, f1
0.0 0.9988 0.6173 0.0398 0.0747
............................................................
TEST: loss, acc, precision, recall, f1
0.0 0.9987 0.6862 0.0425 0.08
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.005845789331942797
............................................................
DEV: loss, acc, precision, recall, f1
0.0 0.999 0.6332 0.138 0.2266
............................................................
TEST: loss, acc, precision, recall, f1
0.0 0.9989 0.6357 0.1443 0.2352
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
######################################################################
EPOCH:  1
current learning rate 3.8e-05
current learning rate 3.8e-05
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.001293129287660122
............................................................
DEV: loss, acc, precision, recall, f1
0.0 0.999 0.7602 0.0517 0.0968
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.0022590577136725187
............................................................
DEV: loss, acc, precision, recall, f1
0.0 0.9991 0.6413 0.315 0.4225
............................................................
TEST: loss, acc, precision, recall, f1
0.0 0.999 0.649 0.3381 0.4445
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
######################################################################
EPOCH:  2
current learning rate 3.61e-05
current learning rate 3.61e-05
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.00027577197761274874
............................................................
DEV: loss, acc, precision, recall, f1
0.0 0.999 0.675 0.4626 0.549
............................................................
TEST: loss, acc, precision, recall, f1
0.0 0.999 0.6767 0.4952 0.5719
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.001385234179906547
............................................................
DEV: loss, acc, precision, recall, f1
0.0 0.9991 0.6782 0.4519 0.5424
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
######################################################################
EPOCH:  3
current learning rate 3.4295e-05
current learning rate 3.4295e-05
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
9.998805035138503e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0 0.9992 0.6966 0.506 0.5862
............................................................
TEST: loss, acc, precision, recall, f1
0.0 0.9991 0.6906 0.5288 0.599
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.0010440845508128405
............................................................
DEV: loss, acc, precision, recall, f1
0.0 0.9991 0.6696 0.541 0.5985
............................................................
TEST: loss, acc, precision, recall, f1
0.0 0.9991 0.6712 0.5717 0.6174
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
######################################################################
EPOCH:  4
current learning rate 3.258025e-05
current learning rate 3.258025e-05
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
7.51480506138203e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0 0.991 0.8018 0.5692 0.6657
............................................................
TEST: loss, acc, precision, recall, f1
0.0 0.9911 0.8091 0.5967 0.6868
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.0010397364385426044
............................................................
DEV: loss, acc, precision, recall, f1
0.0 0.9917 0.7155 0.7515 0.7331
............................................................
TEST: loss, acc, precision, recall, f1
0.0 0.9916 0.7239 0.7711 0.7468
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
######################################################################
EPOCH:  5
current learning rate 3.09512375e-05
current learning rate 3.09512375e-05
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
8.074979268712923e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0 0.9936 0.8021 0.7835 0.7927
............................................................
TEST: loss, acc, precision, recall, f1
0.0 0.9937 0.8107 0.814 0.8124
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.0009250171133317053
............................................................
DEV: loss, acc, precision, recall, f1
0.0101 0.9934 0.7911 0.7834 0.7872
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
######################################################################
EPOCH:  6
current learning rate 2.9403675625e-05
current learning rate 2.9403675625e-05
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.0001146898614242673
............................................................
DEV: loss, acc, precision, recall, f1
0.0 0.9935 0.7828 0.8094 0.7959
............................................................
TEST: loss, acc, precision, recall, f1
0.0 0.9937 0.793 0.8296 0.8109
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.000385234179906547
............................................................
DEV: loss, acc, precision, recall, f1
0.0 0.9934 0.8241 0.7254 0.7717
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
######################################################################
EPOCH:  7
current learning rate 2.7933491843749998e-05
current learning rate 2.7933491843749998e-05
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
3.705186827573925e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0 0.9953 0.7556 0.8613 0.805
............................................................
TEST: loss, acc, precision, recall, f1
0.0 0.9975 0.8483 0.816 0.8319
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.0007454431033693254
............................................................
DEV: loss, acc, precision, recall, f1
0.0 0.9975 0.8332 0.8388 0.836
............................................................
TEST: loss, acc, precision, recall, f1
0.0 0.9961 0.8108 0.8953 0.8509
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
######################################################################
EPOCH:  8
current learning rate 2.6536817251562497e-05
current learning rate 2.6536817251562497e-05
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
6.215864414116368e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0 0.9964 0.8537 0.841 0.8473
............................................................
TEST: loss, acc, precision, recall, f1
0.0 0.998 0.8549 0.8613 0.8581
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
9.464395407121629e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0 0.995 0.7766 0.8666 0.8192
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
######################################################################
EPOCH:  9
current learning rate 2.5209976388984372e-05
current learning rate 2.5209976388984372e-05
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
9.998805035138503e-05
............................................................
DEV: loss, acc, precision, recall, f1
0.0 0.9969 0.7952 0.8439 0.8188
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
current training loss is : 
0.0010440845508128405
............................................................
DEV: loss, acc, precision, recall, f1
0.0 0.995 0.8109 0.7822 0.7963
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
=&==&==&==&==&==&==&==&==&==&==&==&==&==&==&=
Best DEV : overall best loss, acc, precision, recall, f1 
0.0 0.9964 0.8537 0.841 0.8473
scores on TEST when Best DEV:loss, acc, precision, recall, f1 
0.0 0.998 0.8549 0.8613 0.8581
=&==&==&==&==&==&==&==&==&==&==&==&==&==&==&=